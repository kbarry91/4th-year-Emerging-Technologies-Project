{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognition\n",
    "## Introduction\n",
    "This function of this Jupyter notebook is to explain how the python script [Source link to script](https://github.com/kbarry91/Emerging-Technologies/tree/master/4-MNIST%20Digit%20Recognition%20Script) works and to discuss its performance.\n",
    "<br>\n",
    "\n",
    "The aim of the script as discribed in the project brief was to develope a __Digit recognition script__: a _Python script that takes an image ﬁle containing a handwritten digit and identiﬁes the digit using a supervised learning algorithm and the MNIST dataset._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Structure \n",
    "On inital download of the project you will notice the directory only has one folder 'testImages' and a 'digitrec.py' script\n",
    "<br>\n",
    "__testImages:__ Contain images of different sizes and types to test the algorithm.<br>\n",
    "__digitrec.py:__ A python script containing the source code\n",
    "![initial](https://i.imgur.com/8nkerH3.png)\n",
    "Once the program has been compiled and run another folder 'models' will be generated. \n",
    "![after](https://i.imgur.com/LTGgkJI.png)\n",
    "__models:__ Contains saved neural network model to increase performace and decrease wait time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating The program\n",
    "The program has been build to provide simplicity to the user. That is it hides all the complicated workings from the user with a command line GUI that is simple to navigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main Menu \n",
    "The main menu allows the user to view a brief summary of the amount of images used to build and test the model. Aswell as this it also gives 4 options. An option is selected by entering a input into the command line\n",
    "<br>\n",
    "__1.Prepare Dataset and Image Recognition Model:__ Allows user to Build the Digit Recognition model.<br>\n",
    "__2.Upload an Image to predict:__ Allows user to enter an image for the _testImages_ folder and make a prediction.<br>\n",
    "__3.Use MNIST image to predict:__ Allows user to select an image from the MNIST training set to make a prediction.<br>\n",
    "__4.Exit:__ Exits the program\n",
    "![Menu](https://i.imgur.com/1MtWXvs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset and Image Recognition model\n",
    "Select option _1_ allows the user to Prepare the Dataset and to create the image recognition model. The user will be prompted with the option to select how many iterations will be used to train the model.Once the model is build it is saved in the directory as _nn_model_.\n",
    "<br>\n",
    "The program will then display the following statistics\n",
    "1. Summary info, The layers and shape of the model. (Achieved by the code _'model.summary()'_)\n",
    "2. Build progress of the model training  (model.fit(image_train, label_train,\n",
    "                                            batch_size=batch_size,\n",
    "                                            epochs=epochs,\n",
    "                                            verbose=1,\n",
    "                                            validation_data=(image_test, label_test))\n",
    "3. Build complete summary info including loss, accuracy and time taken\n",
    "\n",
    "![build1](https://i.imgur.com/UwQ4DRS.png)\n",
    "![build2](https://i.imgur.com/JEJ0wNK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload an Image to predict\n",
    "Selecting the second menu option (2) allows the user to enter an image and run a predction. Any image that is located in the _testImages_ folder can be used. Once the prediction is complete the program will output in descending order the accuracy percentage of each possible outcome along with a brief note of what the recognised image is.\n",
    "![imgUplaod](https://i.imgur.com/0m11ETt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MNIST image to predict\n",
    "Selcting the third menu option (3) allows the user to harness the scope of the MNIST dataset. The MNIST test set contains 10000 images which are loaded to the program ayt runtime. Selecting a value of 1-10000 will run a prediction on the specified image and output the result.\n",
    "![mnistImg](https://i.imgur.com/m7AIQ2J.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How The program works\n",
    "As the program is is quite large I have __removed some functionality and comments for the purpose of keeping it short__ and explaining how it works. \n",
    "\n",
    "The program has numerous menu options that set variables according to a user input.In this snippet all menu __options have been replaced with hardcoded values.__\n",
    "To view the full commented code view [Source link to script](https://github.com/kbarry91/Emerging-Technologies/tree/master/4-MNIST%20Digit%20Recognition%20Script)\n",
    "\n",
    "### Imports used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gzip          # Must import gzip to allow python to read  and uncompress zip files\n",
    "import timeit        # Timer\n",
    "import numpy as np  # Import numpy as np\n",
    "import sys\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import cv2# Import Cv2  and Imagefor image processing\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import load_model # Import load_models to save model\n",
    "# Import os path to read file\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare The Data\n",
    "The data from the MNIST data set must be loaded into memory before it can be used. Once loaded the data must be reshaped too 60000/10000 items of size 784(28*28). We must also convert the set to a binary representation so it can be used to calculate categorical crossentropy loss on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "60000 training images loaded.\n",
      "10000 test images loaded.\n",
      "Preparing Mnist data Complete!\n"
     ]
    }
   ],
   "source": [
    "(image_train, label_train), (image_test, label_test) = mnist.load_data()\n",
    "imageSize = 784\n",
    "labelOptions = 10\n",
    "\n",
    "# Reshape image data set to 60000 and 10000 elements of size784\n",
    "image_train = image_train.reshape(60000, imageSize)\n",
    "image_test = image_test.reshape(10000, imageSize)\n",
    "\n",
    "# Convert image data to type float 32\n",
    "image_train = image_train.astype('float32')\n",
    "image_test = image_test.astype('float32')\n",
    "\n",
    "# Values are rgb 0-255 . Convert to  0 OR  1\n",
    "image_train /= 255\n",
    "image_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# A binary matrix representation of the input. The classes axis is placed last.\n",
    "# Used for  categorical_crossentropy loss on model\n",
    "label_train = keras.utils.to_categorical(label_train, labelOptions)\n",
    "label_test = keras.utils.to_categorical(label_test, labelOptions)\n",
    "print(label_test)\n",
    "\n",
    "# Output Statistics\n",
    "print(image_train.shape[0], 'training images loaded.')\n",
    "print(image_test.shape[0], 'test images loaded.')\n",
    "print(\"Preparing Mnist data Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above the data has been reshaped and now the training set holds 60,000 images whilst the test set has 10,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model\n",
    "The model must be created and I chose sequential to use a linear stack of layers. We add 3 densely-connected nn-layers, we also set a dropout rate to prevent the model from overfitting while training. For this notebook I have set the epoch value to one to allow one forward pass and one backwards pass of all the training examples. We set the batch size to 128 to set the number of training examples in one forward and backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Building Model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s 385us/step - loss: 0.2480 - acc: 0.9241 - val_loss: 0.1082 - val_acc: 0.9668\n",
      "\n",
      "Model built !\n",
      "Test loss    : 0.10821937542529776\n",
      "Test accuracy: 0.9668\n",
      "Time Taken to train model at  1 epochs = 23.780143140456765\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "# Using Sequental ,Linear stack of layers\n",
    "# Add layer off input shape 784 and output shape of *532\n",
    "# Set fraction of input rates to drop during training\n",
    "model = Sequential()  \n",
    "model.add(Dense(512, activation='relu', input_shape=(784,))) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(labelOptions, activation='softmax'))\n",
    "\n",
    "# Print a string summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Configure model for training\n",
    "# loss = name of objective function\n",
    "# metrics list of metrics to be evaluated by the model\n",
    "\n",
    "# Compile the model\n",
    "# Using sgd gives .86 accur takinhg 18s\n",
    "# Using RMSprop() gives .98 taking 23s\n",
    "# rmsprop = RMSprop(lr=learning_rate) gives .28  taking 25s\n",
    "rmsprop = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Start timer and build model\n",
    "print(\"\\nBuilding Model...\")\n",
    "start_time_train = timeit.default_timer()\n",
    "\n",
    "# Train the model\n",
    "# verbose 1 displays progress bar\n",
    "history = model.fit(image_train, label_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(image_test, label_test))\n",
    "\n",
    "# Stop Timer\n",
    "print(\"\\nModel built !\")\n",
    "end_time_train = timeit.default_timer() - start_time_train\n",
    "\n",
    "score = model.evaluate(image_test, label_test, verbose=0)\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"Time Taken to train model at \", epochs, \"epochs =\", end_time_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make A Predicition\n",
    "Now that the model is created we can make a prediction, As you can see from the following output the neural network works as it should and predicts the correct output with an accuracy of nearly 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Complete\n",
      "System Predicted image is : [2] ,With a accuracy of  99.9658%\n",
      "Actual Image is:  2\n"
     ]
    }
   ],
   "source": [
    "predictionB = model.predict(np.array([image_test[1]], dtype=float))\n",
    "\n",
    "# Get value of closest(MAX) prediction\n",
    "predAccuracy = max(predictionB[0])\n",
    "\n",
    "# Get index of closest(MAX) prediction/actual\n",
    "predIndex = predictionB.argmax(axis=1)\n",
    "actIndex = label_test[1].argmax(axis=0)\n",
    "\n",
    "# Print Prediction results\n",
    "print(\"\\nPrediction Complete\")\n",
    "\n",
    "# Output formatted result to console\n",
    "print(\"System Predicted image is :\",predIndex ,\",With a accuracy of \",\"{0:.4f}%\".format(predAccuracy*100) )\n",
    "print(\"Actual Image is: \", actIndex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs very well in both runtime and prediction accuracy.\n",
    "\n",
    "### Optimzer\n",
    "RMSprop is an unpulished, adaptive learning rate method for reccurent neural networks.for more info see the official keras documentation ![RMSprop](https://keras.io/optimizers/)\n",
    "I decide to use the __RMSprop()__ optimizer as it gave the best runtime/accuracy when running tests against the test images.\n",
    "\n",
    "| Optimizer                 | epoch | batch size | accuracy | Runtime |\n",
    "|---------------------------|-------|------------|----------|---------|\n",
    "| RMSprop(default)          | 1     | 128        | 99.23%   | 18s     |\n",
    "| sgd                       | 1     | 128        | 86%      | 23s     |\n",
    "| RMSprop(lr=learning_rate) | 1     | 128        | 26%      | 25s     |\n",
    "| Adagrad                   | 1     | 128        | 28%      | 25s     |\n",
    "\n",
    "### Epoch\n",
    "I also had to fine tune the epoch value and discovered at a rate of 5 gives the best results. The following table is using the RMSprop.\n",
    "\n",
    "| epoch | batch size | accuracy | Runtime | loss |\n",
    "|-------|------------|----------|---------|------|\n",
    "| 1     | 128        | 96.52%   | 21      | 0.1  |\n",
    "| 5     | 128        | 99.23%   | 107     | 0.07 |\n",
    "| 10    | 128        | 98.32%%  | 218     | 0.05 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and NN results\n",
    "The neural network has proven to be very effective. The model has been able to predict most Images with a near 100% accuracy. I have tested the model against an array of different images such as the official MNIST images,png,jpeg,skewed images, images i have created myself and images of different size.\n",
    "Below are screenshots of some of results outputted by the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "https://keras.io/optimizers/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
